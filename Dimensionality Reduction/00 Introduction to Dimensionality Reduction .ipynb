{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello Flatlanders!\n",
    "===\n",
    "Or soon to be flatlanders at least!\n",
    "\n",
    "In this set of notebooks I'm going to play around with uses for dimensionality reduction \n",
    "I like dimesnionality recution for many reasons, and it's rather useful in program and data analysis. As with all the notebooks here this is just for hobby and toy examples to help me learn the concepts and to offer me a set of examples to go back to when I actually need these techniques.\n",
    "\n",
    "There are many good reasons to like dimensioality reduction, however, if I'm being honest, I like DR because it's pretty. DR is often used to help classify and organize sets of data. You can take data will million or more features and reduce it down to around 100 key components and then in that ~100D space you can craft classifiers and clusters to organize your data. And if you desire, you can go straight to 2 or 3 dimensions from you high dimensional space, or your lower (but still larger than we're visually use to) dimensional space \n",
    "\n",
    "And I'm tired of writing this bit, \n",
    "DR is cool. There's lots of ways to do it,\n",
    "where your smaller dims, x, y, z, are some linear combination of your previous $N$ dims (which is used in many modern classifiers due to speed and memory) or where x, y, z, are some non linear combination ($x=N_{i}^{2}-3N_{j}^{\\frac{1}{2}}$, $y=...$, $z=...$)\n",
    "\n",
    "These different ways to combine your data have large impacts on how your final output is distributed, and depending on how your features are related, some methods will offer more insightful visualizations than others.\n",
    "\n",
    "We'll get to it, I'm tired of this, Hurray I'm going to see if that latex bit worked out..\n",
    "(It did but I forgot the closing ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok, Because I haven't yet gotten to play with this, I'm going to bring in my Free Book dataset. One night I drank a half pint of whiskey and (by hand so as not to violate the website rules) downloaded most of the top 1oo free ebooks from Project Gutenberg. \n",
    "\n",
    "I'm going to do a really cheap parsing where it's all lowercase, and only split on ' ', '\\n', '\\t', '\\r' (Why does '\\r' exist?) We're also going to implement a lantent semantic library based on my lsalib, but all the code will be hosted here because I need to review and update that library anyway, so why not! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All imports will be done here\n",
    "# Not my libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "import math \n",
    "from sklearn.decomposition import ProjectedGradientNMF\n",
    "import re\n",
    "\n",
    "# My personal Libraries \n",
    "import kmlistfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fls = kmlistfi.les('/home/keith/Documents/Databases/Datasets/GutTop100Books/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok for now this is a block copy and paste\n",
    "#    but I'm tired, such is as it is\n",
    "class termDocMatrix(object):\n",
    "    def __init__(self, saveVerbose=True, wcThreshold=2, parseOn=\" \"):\n",
    "        # Get term-document matrix\n",
    "        # transormation/modified weighting of term-doc matrix \n",
    "        # dimensionality reduction\n",
    "        # clustering of documents in reduced space\n",
    "        self.wcThreshold = wcThreshold\n",
    "        self.saveVerbose = saveVerbose\n",
    "        self.parseOn = parseOn\n",
    "        self.mD = {}\n",
    "        self.tdm = []\n",
    "        self.tdmraw = []\n",
    "        self.termraw = []\n",
    "        self.docs = []\n",
    "        self.docsSize = []\n",
    "        self.terms = []\n",
    "        self.docCount = 0\n",
    "        self.idfweight = False\n",
    "        self.P = []\n",
    "        self.Q = []\n",
    "        self.er = []\n",
    "        self.idfs = []\n",
    "        return\n",
    "    def add(self, newThing, docs=\"\"):\n",
    "        def _mergeDict(self, newD, docs=\"\"):\n",
    "            # Grab doc count so far\n",
    "            docIndex = self.docCount\n",
    "            # Get the correct title\n",
    "            if docs == \"\":\n",
    "                docs = docIndex\n",
    "            self.docs.append(docs)\n",
    "            # Add doc size (useful with tdmraw)\n",
    "            tdWeight = float(sum(newD.values()))\n",
    "            if tdWeight == 0:\n",
    "                tdWeight = 1.\n",
    "            self.docsSize.append(tdWeight)\n",
    "            # Add newD to mD\n",
    "            for key in newD:\n",
    "                if key in self.mD:\n",
    "                    if len(self.mD[key]) < self.docCount:\n",
    "                        for i in range(len(self.mD[key]), self.docCount):\n",
    "                            self.mD[key].append(0.)\n",
    "                    self.mD[key].append(newD[key]/float(tdWeight))\n",
    "                else:\n",
    "                    if self.docCount > 0:\n",
    "                        self.mD[key] = [0.]\n",
    "                        for i in range(1, self.docCount):\n",
    "                            self.mD[key].append(0.)\n",
    "                        self.mD[key].append(newD[key]/float(tdWeight))\n",
    "                    else:\n",
    "                        self.mD[key] =  [newD[key]/float(tdWeight)]\n",
    "            self.docCount += 1\n",
    "            return \n",
    "            \n",
    "        \n",
    "        # Ok what was I just given?\n",
    "        if type(newThing) == list:\n",
    "            # Shit.. Ok we can handle this, a list of what?\n",
    "            if len(newThing) > 0:\n",
    "                if type(newThing[0]) == dict:\n",
    "                    # Sweet, it's some dicts, merge them!\n",
    "                    # Wait, what about the title var?\n",
    "                    if (docs != \"\") and (type(docs) == list) and (len(docs) == len(newThing)):\n",
    "                        for i in range(len(newThing)):\n",
    "                            _mergeDict(self, newThing[i], docs[i])\n",
    "                    else:\n",
    "                        for i in range(len(newThing)):\n",
    "                            _mergeDict(self, newThing[i])\n",
    "\n",
    "                elif type(newThing[0]) in [float, long, int, str, unicode]:\n",
    "                    # Well, I mean I don't see why numbers can't be LSA'ized\n",
    "                    # Convert list to dict, then merge\n",
    "                    newD = {}\n",
    "                    for i in range(len(newThing)):\n",
    "                        if newThing[i] in newD:\n",
    "                            newD[newThing[i]] += 1\n",
    "                        else:\n",
    "                            newD[newThing[i]] = 1\n",
    "                    _mergeDict(self, newD, docs)\n",
    "                else:\n",
    "                    raise(TypeError, \"Elements of list are not valid inputs\")\n",
    "\n",
    "                \n",
    "\n",
    "        elif type(newThing) == dict:\n",
    "            # Woo this is simple!\n",
    "            _mergeDict(self, newThing, docs)\n",
    "\n",
    "        elif type(newThing) == str:\n",
    "            # I'm assuming I'm to add this string to the term doc Matrix\n",
    "            strList = newThing.split(self.parseOn)\n",
    "            newD = {}\n",
    "            for i in range(len(strList)):\n",
    "                if strList[i].strip() in newD:\n",
    "                    newD[strList[i].strip()] += 1\n",
    "                else:\n",
    "                    newD[strList[i].strip()] = 1\n",
    "            _mergeDict(self, newD, docs)\n",
    "        return\n",
    "\n",
    "    def weight_idf(self):\n",
    "        # Now we're weighting it, booyea\n",
    "        # The weighting applied here is idf, and assumes td weighting was applied earlier\n",
    "        #   idf: inverse document frequency: log(N/ni)\n",
    "        #     if every doc has word ni, the it zeros out the row\n",
    "        #     Rather than math it, check for it first\n",
    "        self.idfweight = True\n",
    "        for key in self.mD:\n",
    "            # Saving raw state allows matrix to grow w/o redoing everything\n",
    "            # only done if \n",
    "            if self.saveVerbose == True:\n",
    "                self.termraw.append(key)\n",
    "            # This chunk is to check for the idf weight condition:\n",
    "            #   if every doc has the term, then it's not worth 'mathing'\n",
    "            #   and instead can be eliminated\n",
    "            idf = False\n",
    "            if len(self.mD[key]) < self.docCount:\n",
    "                idf = True\n",
    "                for i in range(len(self.mD[key]), self.docCount):\n",
    "                    self.mD[key].append(0.)\n",
    "            # Saving raw matrix\n",
    "            if self.saveVerbose == True:\n",
    "                self.tdmraw.append(self.mD[key])\n",
    "            # Scan row for a zero\n",
    "            if idf == False:\n",
    "                for i in range(len(self.mD[key])):\n",
    "                    if self.mD[key][i] == 0:\n",
    "                        idf = True\n",
    "                        break\n",
    "            # CURRENTLY AN ERROR DUE TO TD WEIGHTING EARLIER: FIXED\n",
    "            if (len(filter(None, self.mD[key])) >= self.wcThreshold) and idf == True:\n",
    "                self.terms.append(key)\n",
    "                self.tdm.append(self.mD[key])\n",
    "        \n",
    "        # Ok now it's actually time to start weighting\n",
    "        self.tdm = numpy.array(self.tdm)\n",
    "        #print len(self.tdm)\n",
    "        for i in range(len(self.tdm)):\n",
    "            #print self.terms[i]\n",
    "            ni = float(numpy.count_nonzero(self.tdm[i]))\n",
    "            if ni == 0:\n",
    "                raise ValueError(\"ARG HOW ARE THERE NO NON ZERO ELIMENTS\")\n",
    "            #print ni, self.docCount\n",
    "            idfValue = math.log(self.docCount/ni)\n",
    "            self.tdm[i] = self.tdm[i] * idfValue\n",
    "            self.idfs.append(idfValue)\n",
    "            \n",
    "        return\n",
    "\n",
    "    def svd(self):\n",
    "        return\n",
    "\n",
    "    def spectralEmbed(self, k, n_neighbors=10):\n",
    "        from sklearn import manifold\n",
    "        se = manifold.SpectralEmbedding(n_components=k, n_neighbors=n_neighbors)\n",
    "        Yse = se.fit_transform(self.tdm)\n",
    "        print len(Yse)\n",
    "        return Yse\n",
    "\n",
    "    def nmf(self, k):\n",
    "        \n",
    "        nmf = ProjectedGradientNMF(n_components=k, max_iter=200)\n",
    "        P = nmf.fit_transform(self.tdm)\n",
    "        Q = nmf.components_.T\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.er = nmf.reconstruction_err_\n",
    "        print \"\\tNMF Error: \", self.er\n",
    "        return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t0 \tHowtoAnalyzePeopleonSight\n",
      "\t1 \tTheRomanceofLust\n",
      "\t2 \tAStudyInScarlet\n",
      "\t3 \tMythsandLegendsofAncientGreeceandRome\n",
      "\t4 \tDonQuixote\n",
      "\t5 \tHeartofDarkness\n",
      "\t6 \tDavidCopperfield\n",
      "\t7 \tAdvofSherlockHolmes\n",
      "\t8 \tThreeMeninaBoat\n",
      "\t9 \tDrJekyllandMrHyde\n",
      "\t10 \tAnneOfGreenGables\n",
      "\t11 \tAChristmasCarol\n",
      "\t12 \tSenseandSensibility\n",
      "\t13 \tPygmalion\n",
      "\t14 \tTheNarrativeoftheLifeOfFrederick\n",
      "\t15 \tEmma\n",
      "\t16 \tDracula\n",
      "\t17 \tAutobiographyofBenjaminFranklin\n",
      "\t18 \tTheLegendofSleepyHollow\n",
      "\t19 \tLesMiserables\n",
      "\t20 \tMySecretLifeV1\n",
      "\t21 \tCrimeandPunishment\n",
      "\t22 \tMaupassantOrginalShortStories\n",
      "\t23 \tDubliners\n",
      "\t24 \tPrideandPrejudice\n",
      "\t25 \tWarAndPeace\n",
      "\t26 \tTheEssaysofMontaigneComplete\n",
      "\t27 \tTheJungle\n",
      "\t28 \tEnglishLiterature\n",
      "\t29 \tHeartofDarkness2\n",
      "\t30 \tEthanFrome\n",
      "\t31 \tofLeavesofGrass\n",
      "\t32 \tDonJuan\n",
      "\t33 \tBeyondGoodAndEvil\n",
      "\t34 \tUncleTomsCabin\n",
      "\t35 \tOccurrenceatOwlCreek\n",
      "\t36 \tWutheringHeights\n",
      "\t37 \tTheBrothersKaramazov\n",
      "\t38 \tHardTimes\n",
      "\t39 \tThroughTheLookingGlass\n",
      "\t40 \tGulliversTravels\n",
      "\t41 \tAlicesAdventuresInWonderland\n",
      "\t42 \tTreasureIsland\n",
      "\t43 \ttheImportanceOfBeingEarnest\n",
      "\t44 \tLeMorteDArthur\n",
      "\t45 \tTheDivineComedy\n",
      "\t46 \tTheHoundoftheBaskervilles\n",
      "\t47 \tOliverTwist\n",
      "\t48 \tForbiddenFruit\n",
      "\t49 \tAModestPurposal\n",
      "\t50 \tJaneEyre\n",
      "\t51 \tYellowWallpaper\n",
      "\t52 \tDemocracyandEducation\n",
      "\t53 \tGrammarandComposition\n",
      "\t54 \tCandide\n",
      "\t55 \tThePicofDorianGray\n",
      "\t56 \tMetamorphosis\n",
      "\t57 \ttheLeiathan\n",
      "\t58 \tADollsHouse\n",
      "\t59 \tCalloftheWild\n",
      "\t60 \tPersuasion\n",
      "\t61 \tSteamItsGenerationAndUse\n",
      "\t62 \tFrankenstein\n",
      "\t63 \tTheTimeMachine\n",
      "\t64 \tTheRepublic\n",
      "\t65 \tTragicalHistoryofDrFaustus\n",
      "\t66 \tThePrince\n",
      "\t67 \tTractatusLogicoPhilosophicus\n",
      "\t68 \tUlysses\n",
      "\t69 \tWaldenandOnCivilDisobedience\n",
      "\t70 \tTheAwakeningandSelectedShortStories\n",
      "\t71 \tSecondTreatiseofGov\n",
      "\t72 \tPeterPan\n",
      "\t73 \tSongsofInnocence\n",
      "\t74 \tBeowulf\n",
      "\t75 \tAnnaKarenina\n",
      "\t76 \tAroundtheWorldin80days\n",
      "\t77 \tKamaSutra\n",
      "\t78 \thuckfin\n",
      "\t79 \tTheIliad\n",
      "\t80 \tMysteriousAffairatStyles\n",
      "\t81 \tCountOfMonteCristo\n",
      "\t82 \tCalculusMadeEasy\n",
      "\t83 \tJosefineMutzenbacher\n",
      "\t84 \tSiddhartha\n",
      "\t85 \tOnLiberty\n",
      "\t86 \tofGreatExpectations\n",
      "\t87 \tMadameBovary\n",
      "\t88 \ttheTaleofPeterRabbit\n",
      "\t89 \tofDemocracyInAmerica\n",
      "\t90 \tTheLifeandAdvofRobinsionCrusoe\n",
      "\t91 \tGrimmsFairyTales\n",
      "\t92 \tTaleOfTwoCities\n",
      "\t93 \tArtistasaYoungMan\n",
      "\t94 \tTheWonderfulWizardOfOz\n",
      "\t95 \tMobyDick\n",
      "\t96 \tAdvofTomSawyer\n",
      "\t97 \ttheJunbleBook\n",
      "\t98 \tTheCompleteWorksofWilliamShakespeare\n"
     ]
    }
   ],
   "source": [
    "tdm = termDocMatrix()\n",
    "for i in range(len(fls)):\n",
    "    flname = fls[i]\n",
    "    fl = open(flname, 'r')\n",
    "    lines = fl.read()\n",
    "    fl.close()\n",
    "    flname = flname.split('/')[-1][:-4]\n",
    "    print '\\t', i, '\\t', flname\n",
    "    line = re.sub('[\\t\\n\\r]', ' ', lines)\n",
    "    line = line.lower()\n",
    "    line = line.split(' ')\n",
    "    tdm.add(line, flname)\n",
    "    \n",
    "tdm.add(\"Goffy Null\", \"Baises Entry\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Worth a shot\n",
    "tdm.weight_idf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/anaconda2/lib/python2.7/site-packages/sklearn/utils/__init__.py:75: DeprecationWarning: Class ProjectedGradientNMF is deprecated; It will be removed in release 0.19. Use NMF instead.'pg' solver is still available until release 0.19.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/keith/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/nmf.py:775: DeprecationWarning: 'pg' solver will be removed in release 0.19. Use 'cd' solver instead.\n",
      "  \" Use 'cd' solver instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNMF Error:  0.156002660872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  4.13811841e-03,   1.48677717e-02],\n",
       "        [  2.82205777e-08,   7.42616800e-08],\n",
       "        [  2.58111799e-06,   6.09902333e-06],\n",
       "        ..., \n",
       "        [  7.73450390e-08,   1.25817763e-06],\n",
       "        [  1.49027598e-07,   1.63649493e-06],\n",
       "        [  3.98865983e-07,   8.23863736e-07]]),\n",
       " array([[  5.49074556e-05,   5.90497159e-03],\n",
       "        [  3.24894763e-05,   1.60198213e-04],\n",
       "        [  4.69171772e-05,   2.21179823e-04],\n",
       "        [  5.42903269e-05,   2.38876730e-04],\n",
       "        [  3.81234843e-05,   1.53530572e-04],\n",
       "        [  3.62109259e-05,   1.82565967e-04],\n",
       "        [  4.17833367e-05,   1.69124509e-04],\n",
       "        [  6.04446723e-05,   1.98360072e-04],\n",
       "        [  6.29309557e-05,   2.27295698e-04],\n",
       "        [  4.82203538e-05,   2.06370416e-04],\n",
       "        [  4.02543859e-05,   1.70923846e-04],\n",
       "        [  4.93879561e-05,   1.99861031e-04],\n",
       "        [  4.14054350e-05,   1.87476124e-04],\n",
       "        [  4.98337108e-05,   2.23851085e-04],\n",
       "        [  4.27496542e-05,   1.73524600e-04],\n",
       "        [  3.53027474e-05,   1.60520385e-04],\n",
       "        [  6.13325159e-05,   2.01036859e-04],\n",
       "        [  5.46385837e-05,   8.40644127e-03],\n",
       "        [  4.25285163e-05,   1.68888434e-04],\n",
       "        [  9.49162320e-05,   5.59411642e-04],\n",
       "        [  1.76578273e-05,   8.12797456e-05],\n",
       "        [  6.22058853e-05,   1.60586885e-04],\n",
       "        [  6.84590123e-05,   2.00653403e-04],\n",
       "        [  6.93537793e-05,   1.94481215e-04],\n",
       "        [  3.45328113e-05,   1.69656155e-04],\n",
       "        [  1.14824838e-04,   1.88657319e-04],\n",
       "        [  7.79585214e-05,   2.61858940e-04],\n",
       "        [  3.75145541e-04,   1.68086359e-04],\n",
       "        [  9.95963373e-05,   1.07101276e-02],\n",
       "        [  3.66289311e-05,   2.32025237e-04],\n",
       "        [  3.75897544e-05,   1.79302062e-04],\n",
       "        [  1.14569692e-04,   4.36870087e-04],\n",
       "        [  1.42998099e-04,   5.59803262e-04],\n",
       "        [  6.19997785e-05,   1.86127212e-04],\n",
       "        [  1.67843339e-04,   1.87598047e-04],\n",
       "        [  5.63227904e-05,   2.55305668e-04],\n",
       "        [  2.11815898e-04,   1.85810378e-04],\n",
       "        [  1.56148853e-04,   1.68783022e-04],\n",
       "        [  5.04020686e-05,   2.32219150e-04],\n",
       "        [  6.20100746e-05,   2.65071212e-04],\n",
       "        [  3.71739669e-05,   1.73768107e-04],\n",
       "        [  5.15181896e-05,   2.27284734e-04],\n",
       "        [  6.35616332e-05,   2.46286389e-04],\n",
       "        [  6.70353861e-05,   3.37258395e-04],\n",
       "        [  9.50580106e-05,   1.78036730e-04],\n",
       "        [  6.85442931e-05,   2.19780860e-04],\n",
       "        [  4.72538530e-05,   2.09505118e-04],\n",
       "        [  5.85281152e-05,   2.07646351e-04],\n",
       "        [  3.48815146e-05,   1.63580173e-04],\n",
       "        [  4.20294272e-05,   2.10984951e-04],\n",
       "        [  9.86362875e-05,   1.97790144e-04],\n",
       "        [  4.73304958e-05,   2.19315098e-04],\n",
       "        [  2.93458639e-05,   2.68885450e-04],\n",
       "        [  1.08535994e-04,   4.98789614e-04],\n",
       "        [  6.40037021e-05,   1.09915776e-02],\n",
       "        [  6.56007817e-05,   2.15112550e-04],\n",
       "        [  5.05391922e-05,   1.71670854e-04],\n",
       "        [  3.99624755e-05,   1.84919947e-04],\n",
       "        [  5.04764642e-05,   2.15426013e-04],\n",
       "        [  5.98046868e-05,   1.69827177e-04],\n",
       "        [  3.87782371e-05,   1.85894737e-04],\n",
       "        [  0.00000000e+00,   3.45150680e-01],\n",
       "        [  4.19151916e-05,   1.86498702e-04],\n",
       "        [  4.08493718e-05,   1.74468375e-04],\n",
       "        [  2.07333904e-04,   2.72681562e-04],\n",
       "        [  1.27434364e-04,   7.97871822e-04],\n",
       "        [  1.47657335e-04,   1.83240591e-04],\n",
       "        [  6.66475273e-05,   1.89058240e-03],\n",
       "        [  1.94127389e-04,   2.58957031e-04],\n",
       "        [  4.42065806e-05,   2.01554400e-04],\n",
       "        [  6.10422060e-05,   1.82280393e-04],\n",
       "        [  5.55804958e-05,   1.76771283e-04],\n",
       "        [  5.43439235e-05,   2.22882679e-04],\n",
       "        [  1.12422773e-04,   4.49669381e-04],\n",
       "        [  3.20086989e-04,   1.28929924e-03],\n",
       "        [  1.68791660e-04,   1.83384596e-04],\n",
       "        [  5.01603535e-05,   2.67162859e-04],\n",
       "        [  4.75607427e-05,   7.29956172e-03],\n",
       "        [  1.51087634e-03,   1.68458776e-04],\n",
       "        [  1.10426228e-04,   4.12759180e-04],\n",
       "        [  5.24212451e-05,   2.32007611e-04],\n",
       "        [  1.45175221e-04,   1.91914600e-04],\n",
       "        [  4.79791374e-04,   2.70766118e-02],\n",
       "        [  3.88644291e-01,   0.00000000e+00],\n",
       "        [  3.99662079e-05,   1.85210949e-04],\n",
       "        [  7.56779794e-05,   1.74074584e-04],\n",
       "        [  3.67680955e-05,   1.70388735e-04],\n",
       "        [  4.54804079e-05,   1.88063502e-04],\n",
       "        [  7.10987241e-05,   2.66792636e-04],\n",
       "        [  3.91471129e-05,   2.82730930e-04],\n",
       "        [  3.09907671e-05,   1.49478218e-04],\n",
       "        [  6.00033379e-05,   1.47396609e-04],\n",
       "        [  4.42522275e-05,   1.83987210e-04],\n",
       "        [  4.92818757e-05,   2.03864031e-04],\n",
       "        [  4.57328492e-05,   2.15073864e-04],\n",
       "        [  5.20615405e-05,   1.82017243e-04],\n",
       "        [  4.73841960e-05,   1.96463330e-04],\n",
       "        [  5.88785779e-05,   2.02036045e-04],\n",
       "        [  1.32039453e-04,   4.97789932e-04],\n",
       "        [  0.00000000e+00,   0.00000000e+00]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.nmf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 128474 100\n"
     ]
    }
   ],
   "source": [
    "print len(tdm.Q), len(tdm.P), len(tdm.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128474 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from matplotlib.pyplot import figure, show\n",
    "import numpy as npy\n",
    "from numpy.random import rand\n",
    "\n",
    "temp = zip(*tdm.P)\n",
    "x = temp[0]\n",
    "y = temp[1]\n",
    "print len(x), len(temp)\n",
    "\n",
    "if 1: # picking on a scatter plot (matplotlib.collections.RegularPolyCollection)\n",
    "\n",
    "    \n",
    "    def onpick3(event):\n",
    "        ind = event.ind\n",
    "        #print ind, type(ind)\n",
    "        if type(ind) == numpy.ndarray:\n",
    "            #print \"YOU\"\n",
    "            ind = ind[0]\n",
    "        print 'onpick3 scatter:', tdm.terms[ind]#, npy.take(x, ind), npy.take(y, ind)\n",
    "\n",
    "    fig = figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    col = ax1.scatter(x, y, picker=True)\n",
    "    #fig.savefig('pscoll.eps')\n",
    "    fig.canvas.mpl_connect('pick_event', onpick3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onpick3 scatter: |\n",
      "onpick3 scatter: \n",
      "onpick3 scatter: =\n",
      "onpick3 scatter: es\n",
      "onpick3 scatter: wie\n",
      "onpick3 scatter: wie\n",
      "onpick3 scatter: der\n",
      "onpick3 scatter: das\n",
      "onpick3 scatter: mich\n",
      "onpick3 scatter: er\n",
      "onpick3 scatter: ich\n",
      "onpick3 scatter: und\n",
      "onpick3 scatter: \n",
      "onpick3 scatter: du\n",
      "onpick3 scatter: ja\n",
      "onpick3 scatter: ja\n",
      "onpick3 scatter: meinen\n",
      "onpick3 scatter: meinen\n",
      "onpick3 scatter: —\n",
      "onpick3 scatter: gases\n",
      "onpick3 scatter: stack\n",
      "onpick3 scatter: willst\n",
      "onpick3 scatter: gut,\n",
      "onpick3 scatter: es,\n",
      "onpick3 scatter: loch\n",
      "onpick3 scatter: ruck\n",
      "onpick3 scatter: ton\n",
      "onpick3 scatter: in\n",
      "onpick3 scatter: _per\n",
      "onpick3 scatter: an\n",
      "onpick3 scatter: ah\n",
      "onpick3 scatter: dicker\n",
      "onpick3 scatter: rosa\n",
      "onpick3 scatter: x\n",
      "onpick3 scatter: x\n",
      "onpick3 scatter: 2\n",
      "onpick3 scatter: y\n",
      "onpick3 scatter: log\n",
      "onpick3 scatter: log\n",
      "onpick3 scatter: o\n",
      "onpick3 scatter: log\n",
      "onpick3 scatter: log\n",
      "onpick3 scatter: [\n",
      "onpick3 scatter: rosa.\n",
      "onpick3 scatter: leopold.\n",
      "onpick3 scatter: stand.\n",
      "onpick3 scatter: stand.\n",
      "onpick3 scatter: albert.\n",
      "onpick3 scatter: stolz,\n",
      "onpick3 scatter: hast,\n",
      "onpick3 scatter: nun,\n",
      "onpick3 scatter: atelier\n",
      "onpick3 scatter: stand.\n",
      "onpick3 scatter: leopold.\n",
      "onpick3 scatter: braver\n",
      "onpick3 scatter: rosa.\n",
      "onpick3 scatter: h.\n",
      "onpick3 scatter: h.\n",
      "onpick3 scatter: a;\n",
      "onpick3 scatter: (2)\n",
      "onpick3 scatter: x,\n",
      "onpick3 scatter: curve\n",
      "onpick3 scatter: b\n",
      "onpick3 scatter: a;\n",
      "onpick3 scatter: p.\n",
      "onpick3 scatter: (p.\n",
      "onpick3 scatter: p.\n",
      "onpick3 scatter: initial\n",
      "onpick3 scatter: nos.\n",
      "onpick3 scatter: obviously\n",
      "onpick3 scatter: chain\n",
      "onpick3 scatter: chain\n",
      "onpick3 scatter: get\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aaaand now I can't undo inline plotting\n",
    "# I stand by matplotlib is a pain\n",
    "# In other news I'm waiting on spectral embedding to finish \n",
    "# in the command line because I guess sleep isn't needed\n",
    "\n",
    "#soo.. I'll do it hsere too\n",
    "k=2\n",
    "n_neighbors=20\n",
    "from sklearn import manifold\n",
    "se = manifold.SpectralEmbedding(n_components=k, n_neighbors=n_neighbors)\n",
    "Yse = se.fit_transform(tdm.tdm)\n",
    "\n",
    "# Run this in your terminal, not here. It isn't optimized and takes about.. well at least 6x longer. \n",
    "#   I'll maybe update that statement when it completes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import kmmessage\n",
    "print len(Yse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmmessage.sms_message_Send(\"\", \"Stuffs done Yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "temp = zip(*Yse)\n",
    "x = temp[0]\n",
    "y = temp[1]\n",
    "print len(x), len(temp)\n",
    "\n",
    "if 1: # picking on a scatter plot (matplotlib.collections.RegularPolyCollection)\n",
    "\n",
    "    \n",
    "    def onpick3(event):\n",
    "        ind = event.ind\n",
    "        print ind, type(ind)\n",
    "        if type(ind) == numpy.ndarray:\n",
    "            print \"YOU\"\n",
    "            ind = ind[0]\n",
    "        print 'onpick3 scatter:', tdm.docs[ind]#, npy.take(x, ind), npy.take(y, ind)\n",
    "\n",
    "    fig = figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    col = ax1.scatter(x, y, picker=True)\n",
    "    #fig.savefig('pscoll.eps')\n",
    "    fig.canvas.mpl_connect('pick_event', onpick3)\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear lord this is why people like linear\n",
    "Get your act together SE, you're pretty much my \n",
    "favorite NLDR method and you're being a total pain.\n",
    "\n",
    "Though, to be fair, SE works a whole hell of a lot better if the high dimensional space has a lot of coverage. From looking at our test sets with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/keith/anaconda2/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
